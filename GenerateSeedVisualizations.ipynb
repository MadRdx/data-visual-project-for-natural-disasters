{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b768350d-c781-474a-95ae-3a829cee836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['year', 'state', 'disaster_name', 'fatalities', 'loss', 'source']\n",
      "\n",
      "=== Events per Year ===\n",
      "    year  event_count\n",
      "0   2000        52007\n",
      "1   2001        48875\n",
      "2   2002        50936\n",
      "3   2003        52956\n",
      "4   2004        52409\n",
      "5   2005        53976\n",
      "6   2006        56400\n",
      "7   2007        59011\n",
      "8   2008        71190\n",
      "9   2009        57398\n",
      "10  2010        62807\n",
      "11  2011        79091\n",
      "12  2012        64503\n",
      "13  2013        59986\n",
      "14  2014        59475\n",
      "15  2015        57907\n",
      "16  2016        56005\n",
      "17  2017        57029\n",
      "18  2018        62697\n",
      "19  2019        67861\n",
      "20  2020        61278\n",
      "21  2021        61389\n",
      "22  2022        69887\n",
      "23  2023        75593\n",
      "24  2024        69493\n",
      "\n",
      "=== Events per Disaster Type ===\n",
      "                 disaster_name  event_count\n",
      "0        Astronomical Low Tide          655\n",
      "1                    Avalanche          771\n",
      "2                     Blizzard        13464\n",
      "3                Coastal Flood         3865\n",
      "4              Cold/Wind Chill        11684\n",
      "5                  Debris Flow         2308\n",
      "6                    Dense Fog        15191\n",
      "7                  Dense Smoke          147\n",
      "8                      Drought        72500\n",
      "9                   Dust Devil          219\n",
      "10                  Dust Storm         1692\n",
      "11              Excessive Heat        19643\n",
      "12     Extreme Cold/Wind Chill        16383\n",
      "13                 Flash Flood        92373\n",
      "14                       Flood        59692\n",
      "15                Freezing Fog          451\n",
      "16                Frost/Freeze        14585\n",
      "17                Funnel Cloud         8325\n",
      "18                        Hail       286505\n",
      "19                        Heat        27645\n",
      "20                  Heavy Rain        28059\n",
      "21                  Heavy Snow        61423\n",
      "22                   High Surf         9692\n",
      "23                   High Wind        79766\n",
      "24                   Hurricane           27\n",
      "25         Hurricane (Typhoon)         1454\n",
      "26                   Ice Storm         9288\n",
      "27            Lake-Effect Snow         2549\n",
      "28             Lakeshore Flood          358\n",
      "29                   Lightning        14350\n",
      "30            Marine Dense Fog           19\n",
      "31                 Marine Hail          831\n",
      "32            Marine High Wind          874\n",
      "33    Marine Hurricane/Typhoon          109\n",
      "34            Marine Lightning            2\n",
      "35          Marine Strong Wind          160\n",
      "36    Marine Thunderstorm Wind        40877\n",
      "37  Marine Tropical Depression           31\n",
      "38       Marine Tropical Storm          584\n",
      "39             Northern Lights            8\n",
      "40                 Rip Current         1691\n",
      "41                      Seiche           65\n",
      "42                       Sleet          728\n",
      "43                 Sneakerwave           47\n",
      "44            Storm Surge/Tide         1522\n",
      "45                 Strong Wind        24432\n",
      "46           Thunderstorm Wind       384874\n",
      "47                     Tornado        35684\n",
      "48         Tropical Depression          549\n",
      "49              Tropical Storm         6784\n",
      "50                     Tsunami           42\n",
      "51                Volcanic Ash           66\n",
      "52            Volcanic Ashfall           77\n",
      "53                  Waterspout         5263\n",
      "54                    Wildfire         8466\n",
      "55                Winter Storm        76076\n",
      "56              Winter Weather        75234\n",
      "\n",
      "=== Fatalities per Year ===\n",
      "    year  fatalities\n",
      "0   2000         477\n",
      "1   2001         469\n",
      "2   2002         498\n",
      "3   2003         443\n",
      "4   2004         370\n",
      "5   2005        1451\n",
      "6   2006         659\n",
      "7   2007         713\n",
      "8   2008         827\n",
      "9   2009         559\n",
      "10  2010         677\n",
      "11  2011        1336\n",
      "12  2012         707\n",
      "13  2013         592\n",
      "14  2014         558\n",
      "15  2015         701\n",
      "16  2016         667\n",
      "17  2017         721\n",
      "18  2018        1058\n",
      "19  2019         731\n",
      "20  2020         897\n",
      "21  2021        1260\n",
      "22  2022        1220\n",
      "23  2023        1463\n",
      "24  2024         993\n",
      "\n",
      "=== Financial Losses per Year (in USD) ===\n",
      "    year          loss\n",
      "0   2000  4.121405e+09\n",
      "1   2001  4.996798e+09\n",
      "2   2002  4.100862e+09\n",
      "3   2003  8.214509e+09\n",
      "4   2004  9.350156e+09\n",
      "5   2005  1.574386e+10\n",
      "6   2006  7.072299e+09\n",
      "7   2007  7.357271e+09\n",
      "8   2008  1.610682e+10\n",
      "9   2009  6.773377e+09\n",
      "10  2010  6.221374e+09\n",
      "11  2011  1.231573e+10\n",
      "12  2012  1.129259e+10\n",
      "13  2013  6.817398e+09\n",
      "14  2014  4.412021e+09\n",
      "15  2015  3.400284e+09\n",
      "16  2016  1.076901e+10\n",
      "17  2017  3.035199e+10\n",
      "18  2018  1.210739e+10\n",
      "19  2019  4.686107e+09\n",
      "20  2020  1.361171e+10\n",
      "21  2021  1.610518e+10\n",
      "22  2022  5.491675e+09\n",
      "23  2023  7.130240e+09\n",
      "24  2024  1.141043e+10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_file = \"US_Disasters_2000_2024.csv\"\n",
    "\n",
    "# Load final merged dataset\n",
    "df = pd.read_csv(output_file)\n",
    "\n",
    "# Standardize column names just in case\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Events per year\n",
    "# ----------------------------\n",
    "events_per_year = df.groupby(\"year\").size().reset_index(name=\"event_count\")\n",
    "print(\"\\n=== Events per Year ===\")\n",
    "print(events_per_year)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Events per disaster type\n",
    "# ----------------------------\n",
    "events_per_type = df.groupby(\"disaster_name\").size().reset_index(name=\"event_count\")\n",
    "print(\"\\n=== Events per Disaster Type ===\")\n",
    "print(events_per_type)\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Fatalities per year\n",
    "# ----------------------------\n",
    "fatalities_per_year = df.groupby(\"year\")[\"fatalities\"].sum().reset_index()\n",
    "print(\"\\n=== Fatalities per Year ===\")\n",
    "print(fatalities_per_year)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Financial losses per year\n",
    "# ----------------------------\n",
    "loss_per_year = df.groupby(\"year\")[\"loss\"].sum().reset_index()\n",
    "print(\"\\n=== Financial Losses per Year (in USD) ===\")\n",
    "print(loss_per_year)\n",
    "\n",
    "# OPTIONAL: Save summary tables\n",
    "events_per_year.to_csv(\"stats_events_per_year.csv\", index=False)\n",
    "events_per_type.to_csv(\"stats_events_per_type.csv\", index=False)\n",
    "fatalities_per_year.to_csv(\"stats_fatalities_per_year.csv\", index=False)\n",
    "loss_per_year.to_csv(\"stats_losses_per_year.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11982b4-ca08-48d2-8f06-433e774415ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== NOAA ===\n",
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2000_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2001_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2002_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2003_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2004_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2005_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2006_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2007_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2008_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2009_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2010_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2011_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2012_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2013_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2014_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2015_c20250818.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2016_c20250818.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2017_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2018_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2019_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2020_c20250702.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2021_c20250520.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2022_c20250721.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2023_c20250731.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NOAA: https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/StormEvents_details-ftp_v1.0_d2024_c20250818.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Madhur\\AppData\\Local\\Temp\\ipykernel_25124\\3830751287.py:47: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved → US_Disasters_2000_2024.csv\n",
      "     year  month    STATE      disaster_name  fatalities     loss source\n",
      "843  2000      1  ALABAMA  Thunderstorm Wind           0   1000.0   NOAA\n",
      "844  2000      1  ALABAMA  Thunderstorm Wind           0   1000.0   NOAA\n",
      "845  2000      1  ALABAMA  Thunderstorm Wind           0  15000.0   NOAA\n",
      "938  2000      1  ALABAMA               Heat           0      0.0   NOAA\n",
      "939  2000      1  ALABAMA               Heat           0      0.0   NOAA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import re\n",
    "from us import states\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# NOAA Storm Events\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def find_noaa_file_for_year(year):\n",
    "    base = \"https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/\"\n",
    "    html = requests.get(base).text\n",
    "\n",
    "    pattern = rf\"StormEvents_details-ftp_v1\\.0_d{year}_c\\d+\\.csv\\.gz\"\n",
    "    matches = re.findall(pattern, html)\n",
    "\n",
    "    if not matches:\n",
    "        return None\n",
    "\n",
    "    return sorted(matches)[-1]  # latest file\n",
    "\n",
    "\n",
    "def extract_year(df):\n",
    "    \"\"\"Extract event year from available columns.\"\"\"\n",
    "    if \"BEGIN_YEAR\" in df.columns:\n",
    "        return df[\"BEGIN_YEAR\"]\n",
    "\n",
    "    if \"YEAR\" in df.columns:\n",
    "        return df[\"YEAR\"]\n",
    "\n",
    "    if \"BEGIN_DATE_TIME\" in df.columns:\n",
    "        return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.year\n",
    "\n",
    "    if \"BEGIN_DATE\" in df.columns:\n",
    "        return pd.to_datetime(df[\"BEGIN_DATE\"], errors=\"coerce\").dt.year\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_month(df):\n",
    "    \"\"\"Extract event month from available NOAA columns.\"\"\"\n",
    "    if \"BEGIN_MONTH\" in df.columns:\n",
    "        return df[\"BEGIN_MONTH\"]\n",
    "\n",
    "    if \"BEGIN_DATE_TIME\" in df.columns:\n",
    "        return pd.to_datetime(df[\"BEGIN_DATE_TIME\"], errors=\"coerce\").dt.month\n",
    "\n",
    "    if \"BEGIN_DATE\" in df.columns:\n",
    "        return pd.to_datetime(df[\"BEGIN_DATE\"], errors=\"coerce\").dt.month\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def flexible_col(df, col, default=0):\n",
    "    \"\"\"Safe getter: returns column if exists, else default.\"\"\"\n",
    "    return df[col] if col in df.columns else default\n",
    "\n",
    "\n",
    "def parse_money(x):\n",
    "    \"\"\"Convert NOAA money strings like '15K', '3.1M' to numeric dollars.\"\"\"\n",
    "    if pd.isna(x) or x == \"0\":\n",
    "        return 0\n",
    "    try:\n",
    "        m = x[-1]\n",
    "        v = float(x[:-1])\n",
    "        if m == \"K\":\n",
    "            return v * 1_000\n",
    "        elif m == \"M\":\n",
    "            return v * 1_000_000\n",
    "        else:\n",
    "            return float(x)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def download_noaa():\n",
    "    dfs = []\n",
    "\n",
    "    for year in range(2000, 2025):\n",
    "        file_name = find_noaa_file_for_year(year)\n",
    "        if not file_name:\n",
    "            print(f\"No NOAA files found for {year}\")\n",
    "            continue\n",
    "\n",
    "        url = f\"https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/{file_name}\"\n",
    "        print(\"Downloading NOAA:\", url)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(io.BytesIO(requests.get(url).content),\n",
    "                             compression=\"gzip\", low_memory=False)\n",
    "\n",
    "            # Add year + month\n",
    "            df[\"year\"] = extract_year(df)\n",
    "            df[\"month\"] = extract_month(df)\n",
    "\n",
    "            # Build columns flexibly\n",
    "            df[\"fatalities\"] = (\n",
    "                flexible_col(df, \"DEATHS_DIRECT\") +\n",
    "                flexible_col(df, \"DEATHS_INDIRECT\")\n",
    "            )\n",
    "\n",
    "            df[\"loss\"] = flexible_col(df, \"DAMAGE_PROPERTY\").apply(parse_money)\n",
    "\n",
    "            df[\"STATE\"] = flexible_col(df, \"STATE\")\n",
    "            df[\"disaster_name\"] = flexible_col(df, \"EVENT_TYPE\", default=\"Unknown\")\n",
    "            df[\"source\"] = \"NOAA\"\n",
    "\n",
    "            dfs.append(df[[\"year\", \"month\", \"STATE\", \"disaster_name\",\n",
    "                           \"fatalities\", \"loss\", \"source\"]])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {year} (error: {e})\")\n",
    "\n",
    "    if dfs:\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# FEMA Disaster Declarations API\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def download_fema():\n",
    "    \"\"\"Download FEMA disaster declarations since 2000.\"\"\"\n",
    "    print(\"Downloading FEMA…\")\n",
    "\n",
    "    url = (\n",
    "        \"https://www.fema.gov/api/open/v1/DisasterDeclarationsSummaries?\"\n",
    "        \"$limit=50000\"\n",
    "    )\n",
    "\n",
    "    data = requests.get(url).json()[\"DisasterDeclarationsSummaries\"]\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    required = [\"fyDeclared\", \"state\", \"incidentType\", \"declarationTitle\"]\n",
    "    for col in required:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    # Extract month from incidentBeginDate if available\n",
    "    if \"incidentBeginDate\" in df.columns:\n",
    "        df[\"month\"] = pd.to_datetime(df[\"incidentBeginDate\"], errors=\"coerce\").dt.month\n",
    "    else:\n",
    "        df[\"month\"] = None\n",
    "\n",
    "    df = df[required + [\"month\"]].copy()\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        \"fyDeclared\": \"year\",\n",
    "        \"state\": \"STATE\",\n",
    "        \"declarationTitle\": \"disaster_name\"\n",
    "    })\n",
    "\n",
    "    df[\"fatalities\"] = None   # FEMA does not include casualties\n",
    "    df[\"loss\"] = None         # FEMA does not include dollar loss\n",
    "    df[\"source\"] = \"FEMA\"\n",
    "\n",
    "    return df[[\"year\", \"month\", \"STATE\", \"disaster_name\", \"fatalities\", \"loss\", \"source\"]]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# USGS Earthquakes  (commented out in your script but updated)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "US_STATE_ABBR = {\n",
    "    \"ALABAMA\":\"AL\",\"ALASKA\":\"AK\",\"ARIZONA\":\"AZ\",\"ARKANSAS\":\"AR\",\"CALIFORNIA\":\"CA\",\"COLORADO\":\"CO\",\n",
    "    \"CONNECTICUT\":\"CT\",\"DELAWARE\":\"DE\",\"FLORIDA\":\"FL\",\"GEORGIA\":\"GA\",\"HAWAII\":\"HI\",\"IDAHO\":\"ID\",\n",
    "    \"ILLINOIS\":\"IL\",\"INDIANA\":\"IN\",\"IOWA\":\"IA\",\"KANSAS\":\"KS\",\"KENTUCKY\":\"KY\",\"LOUISIANA\":\"LA\",\n",
    "    \"MAINE\":\"ME\",\"MARYLAND\":\"MD\",\"MASSACHUSETTS\":\"MA\",\"MICHIGAN\":\"MI\",\"MINNESOTA\":\"MN\",\n",
    "    \"MISSISSIPPI\":\"MS\",\"MISSOURI\":\"MO\",\"MONTANA\":\"MT\",\"NEBRASKA\":\"NE\",\"NEVADA\":\"NV\",\n",
    "    \"NEW HAMPSHIRE\":\"NH\",\"NEW JERSEY\":\"NJ\",\"NEW MEXICO\":\"NM\",\"NEW YORK\":\"NY\",\"NORTH CAROLINA\":\"NC\",\n",
    "    \"NORTH DAKOTA\":\"ND\",\"OHIO\":\"OH\",\"OKLAHOMA\":\"OK\",\"OREGON\":\"OR\",\"PENNSYLVANIA\":\"PA\",\n",
    "    \"RHODE ISLAND\":\"RI\",\"SOUTH CAROLINA\":\"SC\",\"SOUTH DAKOTA\":\"SD\",\"TENNESSEE\":\"TN\",\"TEXAS\":\"TX\",\n",
    "    \"UTAH\":\"UT\",\"VERMONT\":\"VT\",\"VIRGINIA\":\"VA\",\"WASHINGTON\":\"WA\",\"WEST VIRGINIA\":\"WV\",\n",
    "    \"WISCONSIN\":\"WI\",\"WYOMING\":\"WY\"\n",
    "}\n",
    "\n",
    "STATE_ABBR_TO_NAME = {v: k for k, v in US_STATE_ABBR.items()}\n",
    "\n",
    "\n",
    "def extract_us_state(place: str):\n",
    "    \"\"\"Extract U.S. state from USGS 'place' text.\"\"\"\n",
    "    if not isinstance(place, str):\n",
    "        return None\n",
    "\n",
    "    text = place.upper()\n",
    "\n",
    "    for state in US_STATE_ABBR:\n",
    "        if state in text:\n",
    "            return US_STATE_ABBR[state]\n",
    "\n",
    "    tokens = re.findall(r\"[A-Z]{2}\", text)\n",
    "    for tok in tokens:\n",
    "        if tok in STATE_ABBR_TO_NAME:\n",
    "            return tok\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Merge All Datasets\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def build_master():\n",
    "    print(\"\\n=== NOAA ===\")\n",
    "    noaa = download_noaa()\n",
    "\n",
    "    # Uncomment when ready\n",
    "    # print(\"\\n=== FEMA ===\")\n",
    "    # fema = download_fema()\n",
    "\n",
    "    # print(\"\\n=== USGS ===\")\n",
    "    # usgs = download_usgs()\n",
    "\n",
    "    # Normalize NOAA state names (full → abbreviation)\n",
    "    state_map = {s.name: s.abbr for s in states.STATES}\n",
    "    if not noaa.empty:\n",
    "        noaa[\"STATE\"] = noaa[\"STATE\"].replace(state_map)\n",
    "\n",
    "    combined = pd.concat([\n",
    "        noaa[[\"year\", \"month\", \"STATE\", \"disaster_name\", \"fatalities\", \"loss\", \"source\"]],\n",
    "        # fema[[\"year\", \"month\", \"STATE\", \"disaster_name\", \"fatalities\", \"loss\", \"source\"]],\n",
    "        # usgs\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    combined = combined.sort_values(by=[\"year\", \"month\", \"STATE\"], na_position=\"last\")\n",
    "\n",
    "    output_file = \"US_Disasters_2000_2024.csv\"\n",
    "    combined.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"\\nSaved → {output_file}\")\n",
    "    return combined\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = build_master()\n",
    "    print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aca631-77f1-495d-9507-e08a2510ee69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a99338c-70f7-4bae-abfd-f11a5514d53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>STATE</th>\n",
       "      <th>disaster_name</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>loss</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month    STATE      disaster_name  fatalities     loss source\n",
       "843  2000      1  ALABAMA  Thunderstorm Wind           0   1000.0   NOAA\n",
       "844  2000      1  ALABAMA  Thunderstorm Wind           0   1000.0   NOAA\n",
       "845  2000      1  ALABAMA  Thunderstorm Wind           0  15000.0   NOAA\n",
       "938  2000      1  ALABAMA               Heat           0      0.0   NOAA\n",
       "939  2000      1  ALABAMA               Heat           0      0.0   NOAA"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96b142b-f740-4395-b2df-a0a62cc2f844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → US_Disasters_Prediction_2025.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def custom_round(x):\n",
    "    \"\"\"\n",
    "    x: numeric\n",
    "    If decimal >= 0.2 → ceil\n",
    "    else → floor\n",
    "    \"\"\"\n",
    "    frac = x - math.floor(x)\n",
    "    if frac >= 0.2:\n",
    "        return math.ceil(x)\n",
    "    return math.floor(x)\n",
    "\n",
    "\n",
    "def generate_predictions(df):\n",
    "    \"\"\"\n",
    "    df must contain columns:\n",
    "    ['year', 'month', 'STATE', 'disaster_name', 'fatalities', 'loss']\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy().replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 1. Historical means per state & month\n",
    "    # ---------------------------------------\n",
    "    hist = df.groupby([\"STATE\", \"month\"]).agg(\n",
    "        mean_fatalities=(\"fatalities\", \"mean\"),\n",
    "        mean_loss=(\"loss\", \"mean\")\n",
    "    ).reset_index()\n",
    "\n",
    "    hist = hist.fillna(0)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 2. Most likely disaster per state+month\n",
    "    # ---------------------------------------\n",
    "    disaster_counts = (\n",
    "        df.groupby([\"STATE\", \"month\", \"disaster_name\"])\n",
    "          .size()\n",
    "          .reset_index(name=\"count\")\n",
    "    )\n",
    "\n",
    "    most_likely = disaster_counts.loc[\n",
    "        disaster_counts.groupby([\"STATE\", \"month\"])[\"count\"].idxmax()\n",
    "    ][[\"STATE\", \"month\", \"disaster_name\"]]\n",
    "\n",
    "    most_likely = most_likely.rename(columns={\n",
    "        \"disaster_name\": \"most_likely_disaster\"\n",
    "    })\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 3. Generate prediction frame for next year\n",
    "    # ---------------------------------------\n",
    "    next_year = df[\"year\"].max() + 1\n",
    "    all_states = df[\"STATE\"].unique()\n",
    "    all_months = np.arange(1, 12 + 1)\n",
    "\n",
    "    pred_base = pd.MultiIndex.from_product(\n",
    "        [[next_year], all_months, all_states],\n",
    "        names=[\"year\", \"month\", \"STATE\"]\n",
    "    ).to_frame(index=False)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 4. Merge\n",
    "    # ---------------------------------------\n",
    "    pred = pred_base.merge(hist, on=[\"STATE\", \"month\"], how=\"left\")\n",
    "    pred = pred.merge(most_likely, on=[\"STATE\", \"month\"], how=\"left\")\n",
    "\n",
    "    pred[\"mean_fatalities\"] = pred[\"mean_fatalities\"].fillna(0)\n",
    "    pred[\"mean_loss\"] = pred[\"mean_loss\"].fillna(0)\n",
    "    pred[\"most_likely_disaster\"] = pred[\"most_likely_disaster\"].fillna(\"None Observed\")\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 5. Rename\n",
    "    # ---------------------------------------\n",
    "    pred = pred.rename(columns={\n",
    "        \"mean_fatalities\": \"predicted_fatalities\",\n",
    "        \"mean_loss\": \"predicted_loss\"\n",
    "    })\n",
    "\n",
    "    pred = pred.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "\n",
    "    # ---------------------------------------\n",
    "    # 6. APPLY CUSTOM ROUNDING\n",
    "    # ---------------------------------------\n",
    "    pred[\"predicted_fatalities\"] = pred[\"predicted_fatalities\"].apply(custom_round)\n",
    "    pred[\"predicted_loss\"] = pred[\"predicted_loss\"].apply(custom_round)\n",
    "\n",
    "    return pred\n",
    "\n",
    "pred = generate_predictions(df)\n",
    "\n",
    "# Save prediction CSV\n",
    "output_file = \"US_Disasters_Prediction_2025.csv\"\n",
    "pred.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Saved → {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b728be43-c462-48e6-950d-ce22b365cd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>STATE</th>\n",
       "      <th>disaster_name</th>\n",
       "      <th>fatalities</th>\n",
       "      <th>loss</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "      <td>0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>Heat</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NOAA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month    STATE      disaster_name  fatalities     loss source\n",
       "0  2000      1  ALABAMA  Thunderstorm Wind           0   1000.0   NOAA\n",
       "1  2000      1  ALABAMA  Thunderstorm Wind           0   1000.0   NOAA\n",
       "2  2000      1  ALABAMA  Thunderstorm Wind           0  15000.0   NOAA\n",
       "3  2000      1  ALABAMA               Heat           0      0.0   NOAA\n",
       "4  2000      1  ALABAMA               Heat           0      0.0   NOAA"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e0c857-26ee-4c36-87af-9c2f1fb8da88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def analyze_predictions(pred):\n",
    "    print(\"\\n==========================\")\n",
    "    print(\"  ⚡ 2025 PREDICTION ANALYTICS\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 1. Total fatalities & loss per state\n",
    "    # -----------------------------------------------\n",
    "    totals = pred.groupby(\"STATE\").agg(\n",
    "        total_fatalities=(\"predicted_fatalities\", \"sum\"),\n",
    "        total_loss=(\"predicted_loss\", \"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    print(\"\\n--- Total Fatalities & Loss per State ---\")\n",
    "    print(totals.sort_values(\"total_fatalities\", ascending=False).head(10))\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 2. States with maximum fatalities and loss\n",
    "    # -----------------------------------------------\n",
    "    max_fatal_state = totals.loc[totals[\"total_fatalities\"].idxmax()]\n",
    "    max_loss_state = totals.loc[totals[\"total_loss\"].idxmax()]\n",
    "\n",
    "    print(\"\\n--- State with Maximum Fatalities ---\")\n",
    "    print(max_fatal_state)\n",
    "\n",
    "    print(\"\\n--- State with Maximum Loss ---\")\n",
    "    print(max_loss_state)\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 3. Deadliest month per state\n",
    "    # -----------------------------------------------\n",
    "    monthly_fatal = (\n",
    "        pred.groupby([\"STATE\", \"month\"])[\"predicted_fatalities\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    deadliest_month = monthly_fatal.loc[\n",
    "        monthly_fatal.groupby(\"STATE\")[\"predicted_fatalities\"].idxmax()\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Deadliest Month per State ---\")\n",
    "    print(deadliest_month.head(10))\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 4. Most costly month per state\n",
    "    # -----------------------------------------------\n",
    "    monthly_loss = (\n",
    "        pred.groupby([\"STATE\", \"month\"])[\"predicted_loss\"]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    costliest_month = monthly_loss.loc[\n",
    "        monthly_loss.groupby(\"STATE\")[\"predicted_loss\"].idxmax()\n",
    "    ]\n",
    "\n",
    "    print(\"\\n--- Most Expensive Month per State ---\")\n",
    "    print(costliest_month.head(10))\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 5. Nationwide totals\n",
    "    # -----------------------------------------------\n",
    "    nat_fatal = pred[\"predicted_fatalities\"].sum()\n",
    "    nat_loss = pred[\"predicted_loss\"].sum()\n",
    "\n",
    "    print(\"\\n--- Nationwide Totals ---\")\n",
    "    print(f\"Total predicted fatalities nationwide: {nat_fatal}\")\n",
    "    print(f\"Total predicted losses nationwide:    ${nat_loss:,}\")\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 6. Correlation between fatalities & loss\n",
    "    # -----------------------------------------------\n",
    "    corr = pred[\"predicted_fatalities\"].corr(pred[\"predicted_loss\"])\n",
    "\n",
    "    print(\"\\n--- Correlation Fatalities vs Loss ---\")\n",
    "    print(f\"Correlation: {corr:.3f}\")\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # 7. Return all tables for further use\n",
    "    # -----------------------------------------------\n",
    "    return {\n",
    "        \"totals\": totals,\n",
    "        \"deadliest_month\": deadliest_month,\n",
    "        \"costliest_month\": costliest_month,\n",
    "        \"nationwide_totals\": (nat_fatal, nat_loss),\n",
    "        \"correlation\": corr\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af966b31-58a2-4bdc-ba54-a0bb19c66f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "  ⚡ 2025 PREDICTION ANALYTICS\n",
      "==========================\n",
      "\n",
      "\n",
      "--- Total Fatalities & Loss per State ---\n",
      "             STATE  total_fatalities  total_loss\n",
      "15            GUAM                 7    49749018\n",
      "16     GUAM WATERS                 4           0\n",
      "12       E PACIFIC                 3        8592\n",
      "43          NEVADA                 3      688615\n",
      "3          ARIZONA                 2     2445090\n",
      "20   HAWAII WATERS                 2           0\n",
      "33       LOUISIANA                 1    15662322\n",
      "52          OREGON                 1     1945993\n",
      "2   AMERICAN SAMOA                 1     5924654\n",
      "63  VIRGIN ISLANDS                 1      269003\n",
      "\n",
      "--- State with Maximum Fatalities ---\n",
      "STATE                   GUAM\n",
      "total_fatalities           7\n",
      "total_loss          49749018\n",
      "Name: 15, dtype: object\n",
      "\n",
      "--- State with Maximum Loss ---\n",
      "STATE                   GUAM\n",
      "total_fatalities           7\n",
      "total_loss          49749018\n",
      "Name: 15, dtype: object\n",
      "\n",
      "--- Deadliest Month per State ---\n",
      "              STATE  month  predicted_fatalities\n",
      "0           ALABAMA      1                     0\n",
      "12           ALASKA      1                     0\n",
      "32   AMERICAN SAMOA      9                     1\n",
      "41          ARIZONA      6                     1\n",
      "48         ARKANSAS      1                     0\n",
      "60   ATLANTIC NORTH      1                     0\n",
      "72   ATLANTIC SOUTH      1                     0\n",
      "84       CALIFORNIA      1                     0\n",
      "96         COLORADO      1                     0\n",
      "108     CONNECTICUT      1                     0\n",
      "\n",
      "--- Most Expensive Month per State ---\n",
      "              STATE  month  predicted_loss\n",
      "3           ALABAMA      4          409418\n",
      "16           ALASKA      5          391921\n",
      "32   AMERICAN SAMOA      9         1887093\n",
      "45          ARIZONA     10         1558173\n",
      "59         ARKANSAS     12          394822\n",
      "64   ATLANTIC NORTH      5             100\n",
      "81   ATLANTIC SOUTH     10           11024\n",
      "93       CALIFORNIA     10          953126\n",
      "104        COLORADO      9          748588\n",
      "115     CONNECTICUT      8          188996\n",
      "\n",
      "--- Nationwide Totals ---\n",
      "Total predicted fatalities nationwide: 25\n",
      "Total predicted losses nationwide:    $180,337,991\n",
      "\n",
      "--- Correlation Fatalities vs Loss ---\n",
      "Correlation: 0.046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'totals':              STATE  total_fatalities  total_loss\n",
       " 0          ALABAMA                 0     1116835\n",
       " 1           ALASKA                 0     1533308\n",
       " 2   AMERICAN SAMOA                 1     5924654\n",
       " 3          ARIZONA                 2     2445090\n",
       " 4         ARKANSAS                 0     1695480\n",
       " ..             ...               ...         ...\n",
       " 64        VIRGINIA                 0      623667\n",
       " 65      WASHINGTON                 0     8418373\n",
       " 66   WEST VIRGINIA                 0      642890\n",
       " 67       WISCONSIN                 0      765194\n",
       " 68         WYOMING                 0      196053\n",
       " \n",
       " [69 rows x 3 columns],\n",
       " 'deadliest_month':               STATE  month  predicted_fatalities\n",
       " 0           ALABAMA      1                     0\n",
       " 12           ALASKA      1                     0\n",
       " 32   AMERICAN SAMOA      9                     1\n",
       " 41          ARIZONA      6                     1\n",
       " 48         ARKANSAS      1                     0\n",
       " ..              ...    ...                   ...\n",
       " 768        VIRGINIA      1                     0\n",
       " 780      WASHINGTON      1                     0\n",
       " 792   WEST VIRGINIA      1                     0\n",
       " 804       WISCONSIN      1                     0\n",
       " 816         WYOMING      1                     0\n",
       " \n",
       " [69 rows x 3 columns],\n",
       " 'costliest_month':               STATE  month  predicted_loss\n",
       " 3           ALABAMA      4          409418\n",
       " 16           ALASKA      5          391921\n",
       " 32   AMERICAN SAMOA      9         1887093\n",
       " 45          ARIZONA     10         1558173\n",
       " 59         ARKANSAS     12          394822\n",
       " ..              ...    ...             ...\n",
       " 776        VIRGINIA      9          362584\n",
       " 788      WASHINGTON      9         4917503\n",
       " 800   WEST VIRGINIA      9          168593\n",
       " 809       WISCONSIN      6          292510\n",
       " 823         WYOMING      8           69570\n",
       " \n",
       " [69 rows x 3 columns],\n",
       " 'nationwide_totals': (np.int64(25), np.int64(180337991)),\n",
       " 'correlation': np.float64(0.04640587754131313)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473716d-5ddd-493a-ace3-3b1734b5c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
